<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Martingales | Anna Rosengart </title> <meta name="author" content="Anna Rosengart"> <meta name="description" content="A Primer"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://aerosengart.github.io/stats-ml/martingales/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Martingales",
            "description": "A Primer",
            "published": "May 20, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Anna Rosengart </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">curriculum vitae </a> </li> <li class="nav-item "> <a class="nav-link" href="/music/">music </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/stats-ml/">stats &amp; ml</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/measure-theory/">measure theory</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/paper-notes/">paper notes</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Martingales</h1> <p>A Primer</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#definitions">Definitions</a> </div> <ul> <li> <a href="#properties">Properties</a> </li> </ul> <div> <a href="#martingales">Martingales</a> </div> </nav> </d-contents> <p>This post works through highlights of Aaditya Ramdas’ 2018 minicourse<d-cite key="ramdas2018"></d-cite> on martingales at Carnegie Mellon University with some supplemental information taken Durrett<d-cite key="durrett2019"></d-cite> and some definitions from Wikipedia. Additional definitions are from Shafer et al.<d-cite key="shafer2011"></d-cite> and Ramdas et al.<d-cite key="ramdas2022"></d-cite>.</p> <p>This is mostly for my own benefit because I have trouble conceptualizing (and then remembering) many topics in stochastic processes. The main topic of this post will be the <i>martingale</i> (to be more rigously defined later). We can think of a martingale as the amount of wealth a player has at a given round (time point) in a betting game.</p> <hr> <h2 id="definitions">Definitions</h2> <p>We now continue with several “building block” definitions covered in Ramdas et al.<d-cite key="ramdas2022"></d-cite>. We start with the $p$-process, which is sometimes called the <i>anytime-valid $p$-value</i> in other works.</p> <div id="p-process"></div> <div class="definition"> <strong>Definition ($p$-Process).</strong> <br> Let $H_0$ be some hypothesis. A <i>$p$-process</i> is any sequence of $p$-values $(p_t)_{t \in T}$ (with index set $T$) such that $\mathbb{P}_{H_0}(p_\tau \leq a) \leq a$ for all $a \in [0, 1]$ for any arbitrary stopping time, $\tau$. </div> <p>Intuitively, a $p$-process is simply a sequence of $p$-values satisfying the condition that, if we were to stop our sequence at any time (and the stopping time can be whatever we want — even data-dependent!), then the probability that the $p$-value is, at most, any value in $[0, 1]$ cannot exceed that value (kinda like calibration).</p> <div id="e-process"></div> <div class="definition"> <strong>Definition ($e$-Process).</strong> <br> Let $H_0$ be some hypothesis. An <i>e-process</i> is any non-negative sequence $(e_t)_{t \in T}$ (with index set $T$) such that $\mathbb{E}_{H_0}[e_\tau] \leq 1$ for any arbitrary stopping time, $\tau$. </div> <p>Examples of $e$-processes include test martingales and test supermartingales. Related to the $e$-process is the $e$-value.</p> <div id="e-value"></div> <div class="definition"> <strong>Definition ($e$-Value).</strong> <br> Let $H_0$ denote a null hypothesis about the distribution of our data $X = (X_1, \dots, X_\tau)$, which is a sequence of observations with stopping time/sample size $\tau$. An <i>$e$-variable</i> or <i>$e$-statistic</i> is a non-negative random variable $E = E(X)$ such that, for all $P \in H_0$, $\mathbb{E}_P[E] \leq 1$. An <i>$e$-value</i> is a value taken on by $E$, but is commonly used to refer to the $e$-statistic itself. </div> <p>We now turn to ideas in stochastic processes.</p> <div id="random-walk"></div> <div class="definition"> <strong>Definition (Random Walk).</strong> <br> Let $X_1, X_2, \dots$ denote independent and identically distributed random variables in $\mathbb{R}$. The sum of the first $n$, $S_n = X_1 + X_2 + \dots + X_n$, is a <i>random walk</i>. </div> <p>A random walk is a very basic stochastic process. If the walk satisfies the condition that $\mathbb{P}(X_i = 1) = \mathbb{P}(X_i = -1) = \frac{1}{2}$ (i.e. the random variables take values in ${ -1, 1}$ equiprobably), then $S_n$ is a <i>simple random walk</i>.</p> <p>Suppose we want to conceptualize the information we have at time $n$. One way to do so would be to consider the $\sigma$-field generated by $X_1, \dots, X_n$. This leads to the <i>filtration</i>.</p> <div id="filtration"></div> <div class="definition"> <strong>Definition (Filtration).</strong> <br> Let $(\Omega, \mathcal{F}, P)$ be a probability space, and let $I$ be an index set equipped with a total order denoted by $\leq$. For every $i \in I$, let $\mathcal{F}_i$ be a sub-$\sigma$-field of $\mathcal{F}$. A <i>filtration</i>, denoted by $\mathbb{F} = (\mathcal{F}_i)_{i \in I}$ is the set of all such $\mathcal{F}_i$ such that $\mathcal{F}_k \subseteq \mathcal{F}_l$ for all $k \leq l$. </div> <p>Intuitively, a filtration is a collection of sub-$\sigma$-fields of $\mathcal{F}$ that has a non-decreasing order that captures the information had up to a given point (usually in time). We can kind of think about filtrations as keeping track of all of the questions we can answer about our process.</p> <p>At timepoint $t=0$, we know very little about our stochastic process. We know that $(X_t)_{t\in T}$ each take on <i>some</i> value in $\mathcal{F}$, and we know that they <i>must</i> take on values in $\mathcal{F}$. However, that’s all we know. Thus, \(\mathcal{F}_0 = \{ F_0, \emptyset \}\) where $F_0 = \mathcal{F}^{\rvert T \rvert}$, the $\rvert T \rvert$-ary Cartesian power of $\mathcal{F}$.</p> <p>At timepoint $t = 1$, we gain the knowledge of the outcome of $X_1$, and we can therefore answer any question that is only about $X_1$. Some simple examples include “Is $X_1 = 0, 1$ or $2$?” or “Is $X_1$ odd?”. Thus, \(\mathcal{F}_1 = \{ A \times F^{\rvert T \rvert - 1} \rvert A \subseteq \mathcal{P}(\mathcal{F}) \}\) where $\mathcal{P}(S)$ denotes the power set of set $S$. In words, $\mathcal{F}_1$ allows us to answer any question about $X_1$ <i>but nothing about the rest of the process</i>.</p> <p>This sort of relationship continues for all of the sub-$\sigma$-fields in our filtration. Each successive sub-$\sigma$-field, \(\mathcal{F}_{t + 1}\) contains all of the information about our stochastic process’s past development. From our explanation for $t=1$, it is clear that \(\mathcal{F}_t \subseteq \mathcal{F}_{t+1}\). However, $\mathcal{F}_{t+1}$ contains finer grained subsets since we gain knowledge about an additional timepoint in our process.</p> <div class="example"> <strong>Example (Filtration).</strong> <br> Suppose we are flipping a coin two times. Let the tuple $(\Omega, \mathcal{F}, P)$ denote the probability space upon which the random variables representing these flips are defined. The sample space, $\Omega$, is the set $\{ HH, HT, TH, TT \}$. <br> At $t = 0$, $\mathcal{F}_0 = \{ \emptyset, \Omega \}$, since we don't know anything about what the outcomes will be. <br> At $t = 1$, we observe one coin flip, which has to either come out as heads or tails. Thus, $\mathcal{F}_1 = \{ \emptyset, \Omega, \{ HH, HT \}, \{ TH, TT \} \}$. We can interpret the additional two sets as showing us the possible outcomes once we have observed the first flip. $\{ HH, HT \}$ states that, once we see a $H$, that the only possible final results are $HH$ or $HT$. <br> At $t = 2$, we observe the second coin flip, so we know everything about this process. $\mathcal{F}_2 = \{ \emptyset, \Omega, \{ HH, HT \}, \{ TH, TT \}, \{ HH \}, \{ HT \}, \{ TT \}, \{ TH \} \}$. Similar to the case with $\mathcal{F}_1$, after we see both flips, we only have one possible outcome (the one we observed). Thus, we add all singleton sets. Notice that this is $\mathcal{P}(\Omega)$, the power set of the sample space. </div> <p>The natural filtration is the $\sigma$-field generated by $(X_s)_{s \leq t}$.</p> <div id="natural-filtration"></div> <div class="definition"> <strong>Definition (Natural Filtration).</strong> <br> Let $X: T \times \Omega \rightarrow S$ be a stochastic process on probability space $(\Omega, \mathcal{F}, P)$ with (measurable) state space $(S, \Sigma)$. The <i>natural filtration of $\mathcal{F}$ with respect to $X$</i> is the filtration $\mathbb{F}^X = (\mathcal{F}_t^X)_{t \in T}$ where: $$ \mathcal{F}_t^X = \sigma\left(X^{-1}_j(A) \big\rvert j \in T, j \leq t \text{ and } A \in \Sigma\right) \nonumber $$ </div> <p>A stochastic process \((X_t)_{t \in T}\) is said to be <i>adapted to the filtration $\mathbb{F}$</i> if $X_t: \Omega \rightarrow S$ is a $(\mathcal{F}_t, \Sigma)$-measurable function for all $t \in T$.</p> <p>For a filtration $\mathcal{F}_n$ with $n \geq 0$, we call a sequence $H_n$ for $n \geq 1$ <i>predictable</i> if $H_n$ is \(\mathcal{F}_{n-1}\)-measurable for all $n \geq 1$.</p> <h3 id="properties">Properties</h3> <p>Sometimes we need additional assumptions to hold on a given filtration. One is <i>continuity</i>, and another is <i>completeness</i>.</p> <div id="continuous"></div> <div class="definition"> <strong>Definition (Right-Continuity).</strong> <br> Let $\mathbb{F} = (\mathcal{F}_t)_{t \in T}$ be a filtration. If, for all $t \in T$, $\mathcal{F}_t = \bigcap_{s &gt; t} \mathcal{F}_s$, then we call $\mathbb{F}$ <i>right-continuous</i>. </div> <div id="complete"></div> <div class="definition"> <strong>Definition (Complete).</strong> <br> Let $(\Omega, \mathcal{F}, P)$ be a probability space, and let $N_P = \{ A \subseteq \Omega \rvert A \subseteq B, B \in \mathcal{F} \text{ s.t. } P(B) = 0 \}$ be the set of all sets contained in the null set (with respect to $P$). We call a filtration $(\mathcal{F}_t)_{t \in T}$ <i>complete</i> if $N_P \subseteq \mathcal{F}_t$ for all $t$. <br> Equivalently, $(\mathcal{F}_t)_{t \in T}$ is complete if $(\Omega, \mathcal{F}_i, P)$ is a complete measure space for all $t$. </div> <p>We can define the <i>$P$-completion of a $\sigma$-field</i>, $\mathcal{F}$, as the union of $\mathcal{F}$ with all sets $E \in \Omega$ such that $P(E) = 0$.</p> <p>A probability space $(\Omega, \mathcal{F}, P)$ equipped with filtration \(\mathbb{F} = (\mathcal{F}_t)_{t \geq 0}\) where $\mathcal{F}_t$ is a sub-$\sigma$-field of $\mathcal{F}$ is called a <i>filtered probability space</i>.</p> <p>Stochastic processes can also be described by a <i>stopping time</i>, which is another random variable the describes when a stochastic process will display some phenomenon or behavior.</p> <div id="stopping-time"></div> <div class="definition"> <strong>Definition (Stopping Time).</strong> <br> Let $(\Omega, \mathcal{F}, \mathbb{F}, P)$ be a filtered probability space. Let $\tau$ be a random variable defined on this space and taking values in index set $T$. $\tau$ is a <i>stopping time</i> (with respect to $\mathbb{F} = (\mathcal{F}_t)_{t \in T}$) if $\{ \tau \leq t \} \in \mathcal{F}_t$ for all $t \in T$. </div> <p>In simpler terms, $\tau \in { 0, 1, 2, \dots } \cup { \infty }$ is a <i>stopping time</i> if, for any $n \in \mathbb{N}$, the event ${ \tau = n }$ is entirely known just from the information up until time $n$ (i.e. determined by ${X_1, \dots, X_n}$). This can be written as ${ \tau = n } \in \mathcal{F}_n$.</p> <div id="stopping-time-ex"></div> <div class="example"> <strong>Example (Stopping Time).</strong> <br> Let $X_1, X_2, \dots$ be random variables in $\mathbb{R}$. Let $S_n = X_1 + \dots + X_n$. The random variable defined by: $$ \tau = \inf\{t \rvert S_t \geq c \} \nonumber $$ for $c \in \mathbb{R}$ is a stopping time. </div> <p>Constant times (e.g. $\tau = c$ for some $c \in { 0, 1, 2, \dots } \cup { \infty }$) are stopping times, and the minimum and maximum of two stopping times is also a valid stopping time.</p> <hr> <h2 id="martingales">Martingales</h2> <p>Related to stochastic processes and filtrations is the <i>martingale</i>. Here I’ll cover some basic definitions, but interested readers can see my post on martingales for more details.</p> <div id="martingale"></div> <div class="definition"> <strong>Definition (Martingale).</strong> <br> Let $S$ be a Banach space with norm $\rvert \rvert \cdot \rvert \rvert_S$. A stochastic process $X: T \times \Omega \rightarrow S$ on $(\Omega, \mathcal{F}, P)$ with state space $(S, \Sigma)$ is called a <i>martingale with respect to the filtration $\mathbb{F} = \{ \mathcal{F}_t: t \in T \}$ and probability measure $P$</i> if: <ol> <li>$\mathbb{F}$ is a filtration of $(\Omega, \mathcal{F}, P)$</li> <li>$X$ is adapted to $\mathbb{F}$ (i.e. $X_t$ is $\mathcal{F}_t$-measurable for all $t \in T$)</li> <li>For all $t \in T$, $\mathbb{E}_P[ \rvert \rvert X_t \rvert \rvert_S ] &lt; +\infty$</li> <li>For all $s, t \in T$ with $s &lt; t$, and for all subsets $F \in \mathcal{F}_s$, $\mathbb{E}_P[\mathbf{1}\{(X_t - X_s) \in F \}] = 0$</li> </ol> This last condition can be rewritten in terms of the conditional expectation with respect to a sub-$\sigma$-field: $\mathbb{E}_P[ X_t \rvert \mathcal{F}_s ] = 0$. This notation emphasizes that this expectation is an $\mathcal{F}_s$-measurable function. Put more intuitively, albeit with some simplification, a discrete-time martingale is a stochastic process $\{ X(t, \omega): t \in T, \omega \in \Omega\}$ such that, for any $t \in T$: <ol> <li>$\mathbb{E}[\rvert X_t \rvert] &lt; \infty$</li> <li>$\mathbb{E}[X_{t+1} \rvert X_1, \dots, X_t] = X_t$</li> </ol> </div> <p>A relaxation of the condition of a martingale leads to the following object used frequently in game theoretic statistics.</p> <div id="supermartingale"></div> <div class="definition"> <strong>Definition (Supermartingale).</strong> <br> Let $(\Omega, \mathcal{F}, P)$ be a probability space. Let $( X_t )_{t \in T}$ be a stochastic process (with index set $T = \{ 0, 1, \dots \}$ or $T = [0, \infty)$) defined on this space, and let $\mathbb{F} = ( \mathcal{F}_t )_{t \in T}$ be a filtration of sub-$\sigma$-fields of $\mathcal{F}$ (i.e. $\mathcal{F}_t \subseteq \mathcal{F}$ for all $t \in T$). $(X_t, \mathcal{F}_t)$ is a <i>supermartingale</i> if: <ul> <li>$X_t$ is $\mathcal{F}_t$-measurable for all $t \in T$ (i.e. $(X_t)_{t \in T}$ is adapted to $\mathbb{F}$)</li> <li>$X_t$ is integrable for all $t \in T$</li> <li>$\mathbb{E}[X_t \rvert \mathcal{F}_s] \leq X_s$ for all $t \in T$ and all $s &lt; t$ almost surely</li> </ul> We also call the stochastic process $(X_t)_{t \in T}$ a supermartingale if $(X_t, \mathcal{F}_t)$ is a supermartingale and $\mathcal{F}_t$ is the $\sigma$-field generated by $X_t$. </div> <p>More specifically, game theoretic statistics makes use of the <i>test supermartingale</i>.</p> <div id="test-supermartingale"></div> <div class="definition"> <strong>Definition (Test Supermartingale).</strong> <br> A supermartingale $(X_t, \mathcal{F}_t)_{t \in T}$ is called a <i>test supermartingale</i> if $X_t \geq 0$ for all $t$ and $\mathbb{E}[X_0] \leq 1$ (or $X_0 = 1$, which is basically the same as the previous statement if we set $X_t = 1$ for $t &lt; 0$). <br> Similarly, a <i>test martingale</i> is a non-negative martingale such that $\mathbb{E}[X_0] = 1$. </div> <p>Intuitively, a test supermartingale describes the cumulative gain or loss of a player in game where they bet against some hypothesis described by $P$. The initial condition basically specifies the amount of capital the player begins with (1 dollar), and the non-negatively condition ensures the player never loses (cumulatively) more than the initial dollar they they started with.</p> <p>If the player has a lot of money at round $t$ (i.e. large $X_t$), then they have evidence against $P$ being true. This interpretation makes sense when you think about real betting. Winning big is rare at a casino, so having a large payout is associated with low probability events in a game.</p> <p>One property of test supermartingales is the <i>maximal inequality</i>:</p> \[P\left( \underset{ t \leq \infty}{\sup} X_t \geq c \right)\leq \frac{1}{c} \hspace{5mm} \forall c \geq 1\] <p>This inequality states thats the probability (with respect to the probability measure, $P$, of our probability space) that our test supermartingale exceeds some value, $c$, that is at least $1$ is inversely related to the magnitude of $c$. This implies that the probability that a player earns an infinite amount of money in the game is zero.</p> <p>A <i>very</i> important result in probability theory is <a href="https://en.wikipedia.org/w/index.php?title=Ville%27s_inequality&amp;oldid=1213448789" rel="external nofollow noopener" target="_blank">Ville’s inequality</a>, which upperbounds the probability a supermartingale gets at least as big as some chosen value.</p> <div id="ville-inequality"></div> <div class="theorem"> <strong>Theorem (Ville's Inequality).</strong> <ul id="ville" class="tab" data-tab="398f3184-2469-423b-968f-e50e8e283006" data-name="ville"> <li class="active" id="ville-statement"> <a href="#">statement </a> </li> <li id="ville-proof"> <a href="#">proof </a> </li> </ul> <ul class="tab-content" id="398f3184-2469-423b-968f-e50e8e283006" data-name="ville"> <li class="active"> <p>Let $(X_t)_{t = 0}^\infty$ be a non-negative supermartingale. For any positive $a \in \mathbb{R}$:</p> \[\mathbb{P}\left( \underset{n \geq 0}{\sup} X_n \geq a \right) \leq \frac{\mathbb{E}[X_0]}{a}\] </li> <li> <p>Proof to be completed.</p> </li> </ul> </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2025-05-20-martingales.bib"></d-bibliography> <d-article> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Anna Rosengart. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: February 16, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?d4c3ed73337d78e34b10d24890d1fc56"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/tabs.min.js?b8748955e1076bbe0dabcf28f2549fdc"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>